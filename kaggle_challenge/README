In this case I will try to predict median prize of real estate in Boston '70.
I will use boston_housing data from Keras framework. It's one of samples database in Keras.
Procces of preparing and reshaping data step by step you can see in boston_house_price.ipynb.
Process of working and analyzing model step by step you can see in boston_house_price.ipynb

Eeach record in the database describes a Boston suburb or town.
The data was drawn from the Boston Standard Metropolitan Statistical Area in 1970.
The attributes(features) are defined as follow:
Crim - per capita crime rate by town
ZN - proportion of residental land zoned for lots over 25,000 sq.ft.
Indus - proportion of non-retail business acres per town
CHAS - Charles River dummy variable (=1 if tract bounds river;0 otherwise)
NOX - nitric oxides concentration(parts per 10 million)
RM - average number of rooms pew dwelling
AGE: proportion of owner-occupied units built prior to 1940
DIS - weighted distances to five Boston employment centers
RAD - index of accessibility to radial highways
TAX - full-value property-tax-rate per $10,000
PTRATIO - pupil-teacher ratio by town 
Bk - proportion of afro-american by town
LSTAT - % lower status of the population
MEDV - Median value of owner-occupied homes in $1000s

Problems: In this case i got one big problem, database is really small becouse we got only 506 rows and 14 columns(13 features + 1 result)
So the model is exposed to be overfitted. I will use k fold validation, before that i will normalize data.
During training we will be recording metrics MAE(Mean absolute error).
At the end we will get the value which is deviation from real price.

Frameworks:
Keras version 2.4.3
Numpy version 1.17.4
